{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dceb8f8-b62d-42f8-91eb-c10a48732fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Documents\\tensorflow_env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b301359-3c4a-4feb-b45b-4d84108a0f62",
   "metadata": {},
   "source": [
    " I've saved the under_sampled_train_data and test_data_encoded1 files from the R code on my computer with under_sampled_train_data_encoded2 and test_data_encoded1 as name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d1091027-1e25-47cc-88a1-d2fde0fbdad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r\"C:\\Users\\User\\Documents\\Horse Racing\\under_sampled_train_data_encoded2.csv\")\n",
    "#df_train = pd.read_csv(r\"C:\\Users\\User\\Documents\\Horse Racing\\under_sampled_train_data_encoded_interact.csv\")\n",
    "#df_train = pd.read_csv(r\"C:\\Users\\User\\Documents\\Horse Racing\\train_data_encoded1_without_over_under.csv\")\n",
    "df_test = pd.read_csv(r\"C:\\Users\\User\\Documents\\Horse Racing\\test_data_encoded2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98e1d265-52df-401c-8bf3-1dd8206140f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RaceID_To_Norm = pd.read_csv(r\"C:\\Users\\User\\Documents\\Horse Racing\\RaceID_To_Norm.csv\")\n",
    "RaceID_To_Norm = RaceID_To_Norm.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "37b09988-56ff-49c1-b45b-318026b84f50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = df_train[\"RaceOutcome\"]\n",
    "x_train = df_train.drop(['RaceOutcome','Unnamed: 0','HorseID','DamID'], axis=1)\n",
    "y_test = df_test[\"RaceOutcome\"]\n",
    "x_test = df_test.drop(['RaceOutcome','Unnamed: 0','HorseID','DamID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aac2f800-4d54-449e-aa33-d420e08ba9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2495973-8048-46b0-89c6-1a7f57dbd2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class CustomEarlyStop(Callback):\n",
    "    def __init__(self, monitor='val_acc', min_delta=0.5, patience=0):\n",
    "        super(CustomEarlyStop, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "        self.best = 0.95  # Set the threshold to 0.8 for val_acc\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            return\n",
    "\n",
    "        if current > self.best:\n",
    "            print(f\"Stopping training as {self.monitor} exceeded 0.9!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# Usage:\n",
    "custom_early_stop = CustomEarlyStop(monitor='val_acc', min_delta=0.0)  # Set min_delta to 0.0 for this scenario\n",
    "\n",
    "# Model fitting\n",
    "#model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[custom_early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "367b436e-3096-4ecb-b477-878b108a0bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d9ab4e-1066-42d1-8731-ee26c147d12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "2150/2150 - 12s - loss: 0.5619 - acc: 0.7285 - val_loss: 0.5233 - val_acc: 0.7856 - 12s/epoch - 5ms/step\n",
      "Epoch 2/70\n",
      "2150/2150 - 10s - loss: 0.5536 - acc: 0.7321 - val_loss: 0.4791 - val_acc: 0.7877 - 10s/epoch - 5ms/step\n",
      "Epoch 3/70\n",
      "2150/2150 - 9s - loss: 0.5511 - acc: 0.7337 - val_loss: 0.6145 - val_acc: 0.7318 - 9s/epoch - 4ms/step\n",
      "Epoch 4/70\n",
      "2150/2150 - 9s - loss: 0.5523 - acc: 0.7325 - val_loss: 0.5240 - val_acc: 0.7775 - 9s/epoch - 4ms/step\n",
      "Epoch 5/70\n",
      "2150/2150 - 10s - loss: 0.5536 - acc: 0.7313 - val_loss: 0.5615 - val_acc: 0.7519 - 10s/epoch - 5ms/step\n",
      "Epoch 6/70\n",
      "2150/2150 - 11s - loss: 0.5529 - acc: 0.7323 - val_loss: 0.4767 - val_acc: 0.8134 - 11s/epoch - 5ms/step\n",
      "Epoch 7/70\n",
      "2150/2150 - 10s - loss: 0.5506 - acc: 0.7346 - val_loss: 0.5424 - val_acc: 0.7835 - 10s/epoch - 5ms/step\n",
      "Epoch 8/70\n",
      "2150/2150 - 10s - loss: 0.5531 - acc: 0.7323 - val_loss: 0.4999 - val_acc: 0.7848 - 10s/epoch - 5ms/step\n",
      "Epoch 9/70\n",
      "2150/2150 - 10s - loss: 0.5520 - acc: 0.7322 - val_loss: 0.5312 - val_acc: 0.7860 - 10s/epoch - 5ms/step\n",
      "Epoch 10/70\n",
      "2150/2150 - 10s - loss: 0.5562 - acc: 0.7239 - val_loss: 0.5269 - val_acc: 0.7593 - 10s/epoch - 5ms/step\n",
      "Epoch 11/70\n",
      "2150/2150 - 11s - loss: 0.5558 - acc: 0.7275 - val_loss: 0.5318 - val_acc: 0.7846 - 11s/epoch - 5ms/step\n",
      "Epoch 12/70\n",
      "2150/2150 - 10s - loss: 0.5530 - acc: 0.7293 - val_loss: 0.5047 - val_acc: 0.7821 - 10s/epoch - 5ms/step\n",
      "Epoch 13/70\n",
      "2150/2150 - 11s - loss: 0.5527 - acc: 0.7293 - val_loss: 0.4955 - val_acc: 0.8092 - 11s/epoch - 5ms/step\n",
      "Epoch 14/70\n",
      "2150/2150 - 10s - loss: 0.5603 - acc: 0.7203 - val_loss: 0.5066 - val_acc: 0.7845 - 10s/epoch - 5ms/step\n",
      "Epoch 15/70\n",
      "2150/2150 - 11s - loss: 0.5531 - acc: 0.7275 - val_loss: 0.5434 - val_acc: 0.8034 - 11s/epoch - 5ms/step\n",
      "Epoch 16/70\n",
      "2150/2150 - 10s - loss: 0.5592 - acc: 0.7197 - val_loss: 0.5116 - val_acc: 0.7855 - 10s/epoch - 5ms/step\n",
      "Epoch 17/70\n",
      "2150/2150 - 10s - loss: 0.5542 - acc: 0.7282 - val_loss: 0.5163 - val_acc: 0.7997 - 10s/epoch - 5ms/step\n",
      "Epoch 18/70\n",
      "2150/2150 - 10s - loss: 0.5540 - acc: 0.7289 - val_loss: 0.5164 - val_acc: 0.7870 - 10s/epoch - 5ms/step\n",
      "Epoch 19/70\n",
      "2150/2150 - 10s - loss: 0.5522 - acc: 0.7309 - val_loss: 0.5013 - val_acc: 0.7768 - 10s/epoch - 5ms/step\n",
      "Epoch 20/70\n",
      "2150/2150 - 10s - loss: 0.5599 - acc: 0.7213 - val_loss: 0.5226 - val_acc: 0.7404 - 10s/epoch - 5ms/step\n",
      "Epoch 21/70\n",
      "2150/2150 - 10s - loss: 0.5536 - acc: 0.7279 - val_loss: 0.6697 - val_acc: 0.7637 - 10s/epoch - 5ms/step\n",
      "Epoch 22/70\n",
      "2150/2150 - 10s - loss: 0.5549 - acc: 0.7214 - val_loss: 0.4635 - val_acc: 0.8106 - 10s/epoch - 4ms/step\n",
      "Epoch 23/70\n",
      "2150/2150 - 10s - loss: 0.5561 - acc: 0.7178 - val_loss: 0.5847 - val_acc: 0.7637 - 10s/epoch - 5ms/step\n",
      "Epoch 24/70\n",
      "2150/2150 - 10s - loss: 0.5561 - acc: 0.7186 - val_loss: 0.5666 - val_acc: 0.7385 - 10s/epoch - 5ms/step\n",
      "Epoch 25/70\n",
      "2150/2150 - 10s - loss: 0.5805 - acc: 0.6752 - val_loss: 0.6194 - val_acc: 0.7093 - 10s/epoch - 5ms/step\n",
      "Epoch 26/70\n",
      "2150/2150 - 10s - loss: 0.5762 - acc: 0.6757 - val_loss: 0.5324 - val_acc: 0.8038 - 10s/epoch - 5ms/step\n",
      "Epoch 27/70\n",
      "2150/2150 - 10s - loss: 0.5644 - acc: 0.7117 - val_loss: 0.5292 - val_acc: 0.6950 - 10s/epoch - 5ms/step\n",
      "Epoch 28/70\n",
      "2150/2150 - 10s - loss: 0.5651 - acc: 0.7084 - val_loss: 0.6088 - val_acc: 0.7006 - 10s/epoch - 5ms/step\n",
      "Epoch 29/70\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Adjusted hyperparameters\n",
    "hidden_units = 256 # Increased units for more complexity\n",
    "learning_rate = 0.03  # Further reduced learning rate\n",
    "no_epochs = 70  # Increased epochs for more training\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(hidden_units, input_dim=92, activation='relu'))\n",
    "model.add(BatchNormalization())  # Adding batch normalization for stability\n",
    "model.add(Dense(hidden_units, activation='relu'))\n",
    "model.add(Dropout(0.3))  # Increasing dropout for regularization\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Using Adam optimizer with a low learning rate\n",
    "adam = optimizers.Adam(learning_rate)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['acc'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', \n",
    "                                   mode='max', # don't minimize the accuracy!\n",
    "                                   patience=25,\n",
    "                                   restore_best_weights=True)\n",
    "\n",
    "# Training the model\n",
    "model.fit(x_train, y_train, epochs=no_epochs, batch_size=128, verbose=2,validation_data=(x_test, y_test),callbacks=[es]) #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fc7ae5-1e58-4fda-a06c-aeac55b678db",
   "metadata": {},
   "source": [
    "## Add the predict_proba column from test_set to the RaceId_to_Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b402f93-053a-47c0-ba5d-2939ec8c7e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872/872 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted_=model.predict(x_test)\n",
    "\n",
    "predicted_series = pd.Series(predicted_.flatten())  \n",
    "RaceID_To_Norm['predicted_probabilities'] = predicted_series\n",
    "RaceID_To_Norm['RaceOutcome'] = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1da76a24-391a-48bb-9353-0d5be9400172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sort the data by the original index to retain the initial order after grouping\n",
    "RaceID_To_Norm = RaceID_To_Norm.sort_index()\n",
    "\n",
    "# Grouping data by RaceID\n",
    "grouped = RaceID_To_Norm.groupby('RaceID')\n",
    "\n",
    "# Define a function to normalize probabilities using exponential function\n",
    "def normalize_probs(group):\n",
    "    exp_probs = np.exp(group['predicted_probabilities'])\n",
    "    sum_exp_probs = exp_probs.sum()\n",
    "    group['win_probability'] = exp_probs / sum_exp_probs\n",
    "    \n",
    "    # Adjusting for precision to ensure the sum is exactly 1\n",
    "    group['win_probability'] /= group['win_probability'].sum()\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Applying the normalization function to each group (race)\n",
    "Normalized_prob = grouped.apply(normalize_probs).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ddb7d3c-5afe-4a7c-8fcb-7175541abed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "Normalized_prob.to_csv(r'C:\\Users\\User\\Documents\\Horse Racing\\python produced file\\win_probability.parquet', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
